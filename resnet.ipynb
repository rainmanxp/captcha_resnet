{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e05e5d63-6a77-4f61-af53-7a8aa752d26b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-20T09:00:04.338927Z",
     "iopub.status.busy": "2024-02-20T09:00:04.337830Z",
     "iopub.status.idle": "2024-02-20T09:00:04.347430Z",
     "shell.execute_reply": "2024-02-20T09:00:04.346469Z",
     "shell.execute_reply.started": "2024-02-20T09:00:04.338864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/workspace', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '.', '.', 'mnt/workspace/pytorch-captcha-recognition/', 'mnt/workspace/pytorch-captcha-recognition/', 'mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/', '/mnt/workspace/pytorch-captcha-recognition/']\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets,models,transforms\n",
    "\n",
    "import sys\n",
    "sys.path.append('/mnt/workspace/pytorch-captcha-recognition/')\n",
    "print (sys.path)\n",
    "import my_dataset\n",
    "import captcha_setting\n",
    "import importlib\n",
    "importlib.reload(my_dataset)\n",
    "\n",
    "NUM_EPOCH=10\n",
    "batch_size=64\n",
    "lr = 0.001\n",
    "device = torch.device('cuda:0')\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "print(captcha_setting.CLASS_NUM)\n",
    "#help(models.resnet.ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e5200189-7edd-4610-96fb-e959758d1561",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-20T09:01:14.064024Z",
     "iopub.status.busy": "2024-02-20T09:01:14.062949Z",
     "iopub.status.idle": "2024-02-20T09:01:14.400049Z",
     "shell.execute_reply": "2024-02-20T09:01:14.398999Z",
     "shell.execute_reply.started": "2024-02-20T09:01:14.063992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([30, 3, 50, 160]) torch.Size([30, 144])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39msize(),targets\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m### FORWARD AND BACK PROP\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m logits, probas \u001b[38;5;241m=\u001b[39m model(features)\n\u001b[1;32m     35\u001b[0m cost \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, targets)\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "model = models.resnet18(captcha_setting.CLASS_NUM)\n",
    "model.to('cuda:0')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "train_loader = my_dataset.get_train_data_loader() \n",
    "for epoch in range(NUM_EPOCH):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        print(features.size(),targets.size())\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "25559bc1-1f01-46bf-8a4d-2a2227fcf89c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-20T08:38:26.379507Z",
     "iopub.status.busy": "2024-02-20T08:38:26.378781Z",
     "iopub.status.idle": "2024-02-20T08:38:26.387441Z",
     "shell.execute_reply": "2024-02-20T08:38:26.386371Z",
     "shell.execute_reply.started": "2024-02-20T08:38:26.379474Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_data_loader,crtiation, optimizer,schedular, num_epochs=NUM_EPOCH):\n",
    "    \n",
    "    begin_time = time.time()\n",
    "    arr_acc = [] # 用于作图\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"-*-\" * 20)\n",
    "        item_acc = []\n",
    "        schedular.step()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for images, labels in train_data_loader:\n",
    "            #print(images.size(),labels.size())\n",
    "            images.to(device)\n",
    "            labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            opt = model(images.cuda())\n",
    "            # opt = model(images)\n",
    "            _,pred = torch.max(opt,1)\n",
    "            #print(pred,labels,pred.size(),labels.size())\n",
    "            labels = labels.cuda()\n",
    "            loss = crtiation(opt, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "            running_loss += loss.item()*images.size(0)\n",
    "            print(pred,labels,pred.size(),labels.size())\n",
    "            #running_acc += torch.sum(pred==labels)\n",
    "        epoch_loss = running_loss\n",
    "        #epoch_acc = running_acc.double()\n",
    "        print('epoch={}, Loss={:.4f},'.format(epoch, epoch_loss, ))\n",
    "        #item_acc.append(epoch_acc)\n",
    " \n",
    "        #arr_acc.append(item_acc)\n",
    "        \n",
    "        \n",
    "    time_elapes = time.time() - begin_time\n",
    "    print('Training Complete in{:.0f}m {:0f}s'.format(\n",
    "        time_elapes // 60, time_elapes % 60\n",
    "    ))\n",
    "    \n",
    "    return model#,arr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb8ad5a3-fb09-400e-a881-e40ae04e43db",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-02-20T08:38:42.214801Z",
     "iopub.status.busy": "2024-02-20T08:38:42.213759Z",
     "iopub.status.idle": "2024-02-20T08:38:43.175075Z",
     "shell.execute_reply": "2024-02-20T08:38:43.173815Z",
     "shell.execute_reply.started": "2024-02-20T08:38:42.214766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 93, 104, 133, 133,  96,  36,  96,  96, 122,  60,  30,  74,  74, 122,\n",
      "         79,  15, 113,  74,  99,  24,  99,  63,  41,  36,  63,  74,  24,  15,\n",
      "         63,  24], device='cuda:0') tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=0, Loss=642.6569,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 96, 122,  74,  63,  96, 113,  24,  15,  74,  63,  15, 133,  79,  63,\n",
      "         60,  74,  93,  24,  36,  15,  24,  99,  36,  24,  99, 104,  30,  41,\n",
      "         96, 143], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=1, Loss=616.3473,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 99,  93, 113,  63,  41,  96, 113,  36,  36,  74,  51,  96, 113,  24,\n",
      "         15, 133,  24,  99,  15,  24,  79,  60, 104,  30, 122,  74,  63,  63,\n",
      "         15,  74], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=2, Loss=573.0527,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 24, 104,  96,  24,  74,  36,  51,  60,  24, 133,  93,  74, 113, 113,\n",
      "         74,  36,  99,  63,  63, 122,  15,  30, 142,  41,  30,  15,  96,  74,\n",
      "        113,  15], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=3, Loss=525.0059,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 24,  24,  96,  90,  24, 142,  15,  74, 113, 122,  93,  74, 113,  30,\n",
      "         90,  15,  47, 122, 113,  41,  63, 104,  15,  63,   1,  30,  60,  17,\n",
      "        113,  58], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=4, Loss=479.2131,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 30,  58, 142, 143, 113, 101,  41,   1, 130, 128,  17,  15,  15,  73,\n",
      "        103, 120,  74,  60,  63,  47,  15, 104,   2, 122,  25, 113,   1, 142,\n",
      "         90,  98], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=5, Loss=437.6265,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([  2, 103,   1, 101,  90,  17,  15,  30,  98, 127, 143,  58,  74, 142,\n",
      "        142,  42, 130, 120,  63,  47,   1,  73,  42,  25,  25, 104, 122, 128,\n",
      "          4, 113], device='cuda:0') tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=6, Loss=401.2588,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 74, 127,  90,  25,  68, 101,  63,  33,  15, 120,  98,  42, 143,  73,\n",
      "          2, 142, 103,  30,   1, 130, 142,  25,  42,  58, 128,  17,   1,  47,\n",
      "        130, 104], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=7, Loss=369.3241,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([101,  30, 128, 143, 130,  73,  90,  42, 127,  47, 142,   1,  98,  98,\n",
      "        130,  61,  22,   2,   1,  63, 120, 113,  15,  25, 104,  17,  25,  42,\n",
      "         33,  74], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=8, Loss=341.1931,\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "torch.Size([3, 50, 160]) 144\n",
      "tensor([ 87, 113,   1,  47, 130, 130,  98,  41, 127,  73,   2,  61,  25,  42,\n",
      "         15,  25,  42,  22,  67, 142,  33, 143, 101,  98,  90,  17, 128, 104,\n",
      "          1,  30], device='cuda:0') tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.float64) torch.Size([30]) torch.Size([30, 144])\n",
      "epoch=9, Loss=316.6285,\n",
      "Training Complete in0m 0.588015s\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model_resnet = models.resnet18(pretrained=True)\n",
    "    num_fits = model_resnet.fc.in_features\n",
    "    model_resnet.fc = nn.Linear(num_fits,captcha_setting.CLASS_NUM)\n",
    "    model_resnet = model_resnet.to(device)\n",
    "    model_resnet.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_resnet = optim.SGD(model_resnet.parameters(),lr=lr,momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_resnet,step_size=10,gamma=0.1)\n",
    "    train_data_loader = my_dataset.get_train_data_loader()    \n",
    "    model_resnet = train_model(model_resnet,train_data_loader,criterion,optimizer_resnet,exp_lr_scheduler,NUM_EPOCH)\n",
    "    \n",
    "    torch.save(model_resnet.state_dict(),'./capReg.pth')\n",
    "    \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3762ca2-5930-4ebf-bccd-d8733f82bc25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T07:36:56.398644Z",
     "iopub.status.busy": "2024-02-20T07:36:56.397926Z",
     "iopub.status.idle": "2024-02-20T07:36:56.403587Z",
     "shell.execute_reply": "2024-02-20T07:36:56.402707Z",
     "shell.execute_reply.started": "2024-02-20T07:36:56.398611Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924bf091-4e5c-4d78-ba88-ef5be53df845",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "def cnn_main():\n",
    "    cnn = CNN()\n",
    "    cnn.train()\n",
    "    print('init net')\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the Model\n",
    "    train_dataloader = my_dataset.get_train_data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels.float())\n",
    "            predict_labels = cnn(images)\n",
    "            # print(predict_labels.type)\n",
    "            # print(labels.type)\n",
    "            loss = criterion(predict_labels, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "            if (i+1) % 100 == 0:\n",
    "                torch.save(cnn.state_dict(), \"./model.pkl\")   #current is model.pkl\n",
    "                print(\"save model\")\n",
    "        print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
    "    torch.save(cnn.state_dict(), \"./model.pkl\")   #current is model.pkl\n",
    "    print(\"save last model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d0540-6d6f-4924-b741-ff5ccd51a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, crtiation, optimizer,schedular, num_epochs=NUM_EPOCH):\n",
    "\n",
    "    train_dataloader = my_dataset.get_train_data_loader()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_dataloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310c20e-8b84-449a-b928-7da760b79b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    model_resnet = models.resnet18(pretrained=True)\n",
    "    num_fits = model.fc.in_features\n",
    "    model_resnet.fc = nn.Linear(num_fits,captcha_setting.CLASS_NUM)\n",
    "    model_resnet = model_resnet.to(device)\n",
    "    model_resnet.cuda()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_resnet = optim.SGD(model_resnet.parameters(),lr=lr,momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_resnet,step_size=10,gamma=0.1)\n",
    "    train_data_loader = my_dataset.get_train_data_loader()    \n",
    "    model_resnet,acc = train_model(model_resnet,train_data_loader,criterion,optimizer_resnet,exp_lr_scheduler,NUM_EPOCH)\n",
    "    \n",
    "    torch.save(model_ft.state_dict(),'./model/capReg.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9185e33-41bc-480e-a5ad-86a5a7184450",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2024-02-19T08:58:28.349023Z",
     "iopub.status.busy": "2024-02-19T08:58:28.348335Z",
     "iopub.status.idle": "2024-02-19T08:58:31.973402Z",
     "shell.execute_reply": "2024-02-19T08:58:31.972113Z",
     "shell.execute_reply.started": "2024-02-19T08:58:28.348992Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/Train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 74\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n\u001b[1;32m     59\u001b[0m data_tranforms\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m:transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     61\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomResizedCrop(\u001b[38;5;241m50\u001b[39m), \u001b[38;5;66;03m# 随机裁剪为不同的大小和宽高比,缩放所为制定的大小\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     ])\n\u001b[1;32m     72\u001b[0m }\n\u001b[0;32m---> 74\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x : CustomImageLoader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# 默认目录为根目录，配搭文件中使用全路径\u001b[39;00m\n\u001b[1;32m     75\u001b[0m                                         txt_path\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x)), \u001b[38;5;66;03m# 标签文件\u001b[39;00m\n\u001b[1;32m     76\u001b[0m                                         data_transforms\u001b[38;5;241m=\u001b[39mdata_tranforms,\n\u001b[1;32m     77\u001b[0m                                         dataset\u001b[38;5;241m=\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     78\u001b[0m                   }\n\u001b[1;32m     80\u001b[0m dataloders \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x],\n\u001b[1;32m     81\u001b[0m                                                  batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     82\u001b[0m                                                  shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     84\u001b[0m dataset_sizes \u001b[38;5;241m=\u001b[39m {x: \u001b[38;5;28mlen\u001b[39m(image_datasets[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]} \u001b[38;5;66;03m# 数据大小\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 74\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n\u001b[1;32m     59\u001b[0m data_tranforms\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m:transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     61\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mRandomResizedCrop(\u001b[38;5;241m50\u001b[39m), \u001b[38;5;66;03m# 随机裁剪为不同的大小和宽高比,缩放所为制定的大小\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     ])\n\u001b[1;32m     72\u001b[0m }\n\u001b[0;32m---> 74\u001b[0m image_datasets \u001b[38;5;241m=\u001b[39m {x : \u001b[43mCustomImageLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 默认目录为根目录，配搭文件中使用全路径\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtxt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 标签文件\u001b[39;49;00m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_tranforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     78\u001b[0m                   }\n\u001b[1;32m     80\u001b[0m dataloders \u001b[38;5;241m=\u001b[39m {x: torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(image_datasets[x],\n\u001b[1;32m     81\u001b[0m                                                  batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     82\u001b[0m                                                  shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     84\u001b[0m dataset_sizes \u001b[38;5;241m=\u001b[39m {x: \u001b[38;5;28mlen\u001b[39m(image_datasets[x]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m]} \u001b[38;5;66;03m# 数据大小\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m, in \u001b[0;36mCustomImageLoader.__init__\u001b[0;34m(self, img_path, txt_path, dataset, data_transforms, loader)\u001b[0m\n\u001b[1;32m     29\u001b[0m im_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m im_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtxt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m files:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;66;03m#/x/y/a.jpg 1\u001b[39;00m\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;66;03m#/x/y/b.jpg 2\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         items \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/Train.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "\n",
    "NUM_EPOCH = 100 # 默认迭代次数\n",
    "batch_size = 64\n",
    "device = torch.device('cuda:0') # 默认使用 GPU\n",
    "NUMCLASS = 4 # 类别数\n",
    "\n",
    "def default_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "class CustomImageLoader(data.Dataset): # 定义自己的数据类\n",
    "    ##自定义类型数据输入\n",
    "    def __init__(self, img_path, txt_path, dataset = '', data_transforms=None, loader = default_loader):\n",
    "        im_list = []\n",
    "        im_labels = []\n",
    "        with open(txt_path, 'r') as files:\n",
    "            for line in files:\n",
    "                #/x/y/a.jpg 1\n",
    "                #/x/y/b.jpg 2\n",
    "                items = line.split()\n",
    "                im_list.append(items[0])\n",
    "                im_labels.append(int(items[1]))\n",
    "        self.imgs = im_list\n",
    "        self.labels = im_labels\n",
    "        self.data_tranforms = data_transforms\n",
    "        self.loader = loader\n",
    "        self.dataset = dataset\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    " \n",
    "    def __getitem__(self, item):\n",
    "        img_name = self.imgs[item]\n",
    "        label = self.labels[item]\n",
    "        img = self.loader(img_name)\n",
    " \n",
    "        if self.data_tranforms is not None:\n",
    "            try:\n",
    "                img = self.data_tranforms[self.dataset](img)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(img_name))\n",
    "        return img, label\n",
    "    \n",
    "data_tranforms={\n",
    "    'Train':transforms.Compose([\n",
    "        transforms.RandomResizedCrop(50), # 随机裁剪为不同的大小和宽高比,缩放所为制定的大小\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]) # 各通道颜色的均值和方差,用于归一化\n",
    "    ]),\n",
    "    'Test':transforms.Compose([\n",
    "        transforms.Resize(64), # 变换大小\n",
    "        transforms.CenterCrop(50), # 中心裁剪\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    " \n",
    "image_datasets = {x : CustomImageLoader('/', # 默认目录为根目录，配搭文件中使用全路径\n",
    "                                        txt_path=('./data/{0}.txt'.format(x)), # 标签文件\n",
    "                                        data_transforms=data_tranforms,\n",
    "                                        dataset=x) for x in ['Train', 'Test']\n",
    "                  }\n",
    " \n",
    "dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=True) for x in ['Train', 'Test']}\n",
    " \n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['Train', 'Test']} # 数据大小\n",
    "\n",
    "def train_model(model, crtiation, optimizer,schedular, num_epochs=NUM_EPOCH):\n",
    "    \n",
    "    begin_time = time.time()\n",
    "    best_weights = copy.deepcopy(model.state_dict())#copy the weights from the model\n",
    "    best_acc = 0.0\n",
    "    arr_acc = [] # 用于作图\n",
    " \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"-*-\" * 20)\n",
    "        item_acc = []\n",
    "        for phase in ['Train', 'Test']:\n",
    "            if phase=='Train':\n",
    "                schedular.step()\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    " \n",
    "            for images, labels in dataloders[phase]:\n",
    "                images.to(device)\n",
    "                labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    " \n",
    "                with torch.set_grad_enabled(phase=='Train'):\n",
    "                    opt = model(images.cuda())\n",
    "                    # opt = model(images)\n",
    "                    _,pred = torch.max(opt,1)\n",
    "                    labels = labels.cuda()\n",
    "                    loss = crtiation(opt, labels)\n",
    "                    if phase=='Train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    " \n",
    "                running_loss += loss.item()*images.size(0)\n",
    "                running_acc += torch.sum(pred==labels)\n",
    "            epoch_loss = running_loss/dataset_sizes[phase]\n",
    "            epoch_acc = running_acc.double()/dataset_sizes[phase]\n",
    "            print('epoch={}, Phase={}, Loss={:.4f}, ACC:{:.4f}'.format(epoch, phase, \n",
    "                                                                       epoch_loss, epoch_acc))\n",
    "            item_acc.append(epoch_acc)\n",
    " \n",
    "            if phase == 'Test' and epoch_acc>best_acc:\n",
    "                # Upgrade the weights\n",
    "                best_acc=epoch_acc\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "        arr_acc.append(item_acc)\n",
    "        \n",
    "    time_elapes = time.time() - begin_time\n",
    "    print('Training Complete in{:.0f}m {:0f}s'.format(\n",
    "        time_elapes // 60, time_elapes % 60\n",
    "    ))\n",
    "    print('Best Val ACC: {:}'.format(best_acc))\n",
    " \n",
    "    model.load_state_dict(best_weights) # 保存最好的参数\n",
    "    return model,arr_acc\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    num_fits = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_fits, NUMCLASS) # 替换最后一个全连接层\n",
    "    model_ft = model_ft.to(device)\n",
    "    model_ft.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "    train_data_loader = my_dataset.get_train_data_loader()    \n",
    "    model_ft,arr_acc = train_model(model_ft,train_data_loader, criterion, optimizer_ft, exp_lr_scheduler, NUM_EPOCH)\n",
    "    ## 保存模型 \n",
    "    torch.save(model_ft.state_dict(), './model/my_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9657842b-4c85-43e5-a9e7-93df03b48574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
